<!DOCTYPE html>
<html>
  <head>
    <title>iPong</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../assets/styles/styles.css">
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdn.jsdelivr.net/npm/flowbite@2.5.2/dist/flowbite.min.css" rel="stylesheet" />
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <link rel="icon" href="../assets/icons/logo2.svg" type="image/svg+xml">
  </head>

  <body class="bg-gray-100 text-gray-800">

    <!-- Top Navigation Bar -->
    <nav id="navbar" class="fixed top-0 left-0 right-0 z-50 navbar-transition">
      <div class="container mx-auto px-4 py-3 flex justify-between items-center">
        <!-- Title on the Left -->
        <h1 class="text-2xl font-bold navbar-text px-5 py-1 flex-1"><a href="../">iPong</a></h1>
  
        <!-- Buttons on the Right -->
        <div class="hidden lg:flex space-x-6 px-5 py-1">
          <a href="../design" class="navbar-link font-semibold underline decoration-4 underline-offset-4">Design</a>
          <button id="dropdownHoverButton" data-dropdown-toggle="dropdownHover" data-dropdown-trigger="hover" 
            class="navbar-link flex font-semibold hover:underline decoration-2 underline-offset-4" type="button">
            <a href="../implementation/">Implementation</a>
            <svg class="-mr-1 size-5 text-gray-400" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true" data-slot="icon">
              <path fill-rule="evenodd" d="M5.22 8.22a.75.75 0 0 1 1.06 0L10 11.94l3.72-3.72a.75.75 0 1 1 1.06 1.06l-4.25 4.25a.75.75 0 0 1-1.06 0L5.22 9.28a.75.75 0 0 1 0-1.06Z" clip-rule="evenodd" />
            </svg>
          </button>
          <!-- Dropdown menu -->
          <div id="dropdownHover" class="mt-2 hidden bg-white shadow-lg rounded-lg py-2 w-48">
            <ul class="py-2 text-sm text-gray-700 dark:text-gray-200" aria-labelledby="dropdownHoverButton">
              <li><a href="../implementation/vision/" class="block px-4 py-2 font-semibold text-gray-700 hover:bg-gray-100 hover:text-gray-900">Vision</a></li>
              <li><a href="../implementation/trajectory/" class="block px-4 py-2 font-semibold text-gray-700 hover:bg-gray-100 hover:text-gray-900">Trajectory</a></li>
              <li><a href="../implementation/control/" class="block px-4 py-2 font-semibold text-gray-700 hover:bg-gray-100 hover:text-gray-900">Control</a></li>
            </ul>
          </div>
          <a href="../results" class="navbar-link font-semibold hover:underline decoration-2 underline-offset-4">Results</a>
          <a href="../conclusion" class="navbar-link font-semibold hover:underline decoration-2 underline-offset-4">Conclusion</a>
          <a href="../team" class="navbar-link font-semibold hover:underline decoration-2 underline-offset-4">Team</a>
          <a href="../resources" class="navbar-link font-semibold hover:underline decoration-2 underline-offset-4">Resources</a>
        </div>
  
        <!-- Mobile Menu Button -->
        <button id="dropdownDefaultButton" data-dropdown-toggle="mobileMenu" 
          data-dropdown-offset-distance="20"
          class="lg:hidden navbar-link" type="button">
          <svg class="w-6 h-6" xmlns="http://www.w3.org/2000/svg" fill="none" stroke="currentColor" viewBox="0 0 24 24" stroke-width="2">
            <path stroke-linecap="round" stroke-linejoin="round" d="M4 6h16M4 12h16M4 18h16" />
          </svg>
          </button>
      </div>
    </nav>
  
    <!-- Mobile Menu -->
    <div id="mobileMenu" class="lg:hidden z-20 hidden bg-gray-400 shadow-lg rounded-lg py-2  px-20 w-full absolute top-full left-0">
      <ul class="py-2 text-gray-700 dark:text-gray-200" aria-labelledby="dropdownDefaultButton">
        <li><a href="../design" class="block px-4 py-2 navbar-link font-semibold underline decoration-4 underline-offset-4 hover:bg-gray-100 hover:text-gray-900">Design</a></li>
        <li><a href="../implementation" class="block px-4 py-2 navbar-link font-semibold hover:bg-gray-100 hover:text-gray-900">Implementation</a></li>
        <li><a href="../results" class="block px-4 py-2 navbar-link font-semibold hover:bg-gray-100 hover:text-gray-900">Results</a></li>
        <li><a href="../conclusion" class="block px-4 py-2 navbar-link font-semibold hover:bg-gray-100 hover:text-gray-900">Conclusion</a></li>
        <li><a href="../team" class="block px-4 py-2 navbar-link font-semibold  hover:bg-gray-100 hover:text-gray-900">Team</a></li>
        <li><a href="../resources" class="block px-4 py-2 navbar-link font-semibold hover:bg-gray-100 hover:text-gray-900">Resources</a></li>
      </ul>
    </div>

    <!-- Hero Section -->
    <section class="relative bg-gray-900 h-[400px] flex items-center justify-center">
      <img src="../assets/images/design.jpg" 
          alt="Hero Image" 
          class="absolute inset-0 w-full h-full object-cover opacity-50">
      <div class="text-center relative z-10">
        <h1 class="text-5xl font-bold text-white drop-shadow-lg">Design</h1>
      </div>
    </section>

    <!-- Design Criteria -->
    <section id="criteria" class="py-20 bg-gray-white">
      <div class="container mx-auto px-4 text-center">
        <h2 class="text-4xl font-bold text-gray-800 mb-4">Design Criteria</h2>
        <p class="text-gray-600 max-w-3xl mx-auto text-left mb-5">
          The goal of our project is to implement Vision and Model Predictive Control (MPC) into a Sawyer arm to enable it to detect and intercept a ball in real time. 
          Specifically, the sawyer should be able to:
        </p>
        <ul class="list-disc list-inside space-y-1 text-gray-700 mx-auto max-w-3xl text-start pl-4">
          <li><b>See</b> the ball and knows its spatial position and velocity.</li>
          <li><b>Detect</b> whether or not the ball is flying towards it.</li>
          <li><b>Estimate</b> ball trajectory and determine a point to intercept the ball.</li>
          <li><b>Move</b> arm to intercept the ball.</li>
        </ul>
      </div>
    </section>

    <!-- See Ball -->
    <section id="seeball" class="py-16 bg-white">
      <div class="container mx-auto px-4 mb-12">
        <h2 class="text-4xl font-bold text-gray-800 text-center mb-8">
          <span class="text-5xl text-blue-600">Seeing</span> the Ball
        </h2>
        <p class="text-gray-600 max-w-3xl mx-auto text-center leading-relaxed">
          The sawyer robot needs to know accurately where the ball is in relation to its own position. In order words, we need the X, Y, Z 
          coordinate of the ball in the robot's frame.
        </p>
      </div>
      <div class="container mx-auto px-8 max-w-6xl">
        <div class="grid grid-cols-3 gap-12 items-center mb-5">
          <div>
            <img src="../assets/images/realsense.png" 
                alt="RealSense Image" 
                class="rounded-lg w-full">
          </div>
          <div class="col-span-2">
            <h2 class="text-2xl text-gray-700 font-bold mb-4">➪ Camera</h2>
            <p class="text-gray-700 leading-relaxed mb-3">
              We use the RealSence depth camera to obtain both the RGB and depth images, utilizing its built-in stereo vision. 
              The camera is positioned such that the ball is in view, and the depth information of the ball can then be obtained from the depth image. 
              The camera is at a fixed position from the sawyer so that the position of the ball in the camera frame can be easily transformed into the robot frame.
            </p>
            <p class="text-gray-500 leading-relaxed"><b>Tradeoff: </b>RealSense D435 Camera is readily available in the lab and with ROS packages available, however they have limitations 
            including 30 FPS limit on RGB images and accurate depth range of up to 3 meters. Additionally, we are limited to one camera due to budget.
            This leads to vision with shorter range, narrower field of view, and increased latency.</p>
          </div>
        </div>
        <div class="border-t border-gray-200 mb-5"></div>
        <div class="grid grid-cols-3 gap-12 items-center mb-5">
          <div>
            <img src="../assets/images/hsv.png" 
                alt="RealSense Image" 
                class="rounded-lg w-full">
          </div>
          <div class="col-span-2">
            <h2 class="text-2xl text-gray-700 font-bold mb-4">➪ Locating Ball</h2>
            <p class="text-gray-700 leading-relaxed mb-3">
              We use a simple HSV thresholding method to detect the ball within the RGB image from the camera. We filter the RGB image with a 
              set of constraints on the values of H, S, and V such that only the ball pixels are left. We can then obtain the 2D coordinate of the ball 
              with a simple averaging operation, and then combine it with depth to obtain the final 3D coordinate of the ball.
            </p>
            <p class="text-gray-500 leading-relaxed"><b>Tradeoff: </b>HSV thresholding is very simple and overall effective, but relies on having little 
            background noise. We used a combination of multiple techniques including Kalman filtering, DBSCAN clustering, and depth thresholding to reduce noise 
            but the end result is still not noise-proofed. Better and more robust ball detection may require more advanced feature-based ball detection methods 
            like using algorithms from OpenCV or training neural networks.</p>
          </div>
        </div>
        <div class="border-t border-gray-200 mb-5"></div>
        <div class="grid grid-cols-3 gap-12 items-center">
          <div>
            <img src="../assets/images/locate_cam.jpeg" 
                alt="Locate Cam Image" 
                class="rounded-lg w-full">
          </div>
          <div class="col-span-2">
            <h2 class="text-2xl text-gray-700 font-bold mb-4">➪ Frame Transformation</h2>
            <p class="text-gray-700 leading-relaxed">
              To transform ball coordinate in camera frame to the robot frame, we utilize AR tag tracking to simplify the setup process. We put an AR tag 
              on the back of the camera, which can then be viewed by the Sawyer head camera to compute the position of the camera in the robot frame. 
              Afterwards, for any 3D coordinate of the ball in camera frame, we can simply perform a frame transform to get the coordinate in the robot frame.
            </p>
          </div>
        </div>
      </div>
    </section> 

    <!-- Detect & Predict Ball -->
    <section id="detectball" class="py-16 bg-gray-100">
      <div class="container mx-auto px-4 mb-12">
        <div class="mx-auto max-w-3xl">
          <h2 class="text-4xl font-bold text-gray-800 mb-8">
            <div class="text-left">
              <span class="text-5xl text-blue-600">Detecting</span> Ball Movement
            </div>
            <div class="text-center">
              <span class="text-6xl">+</span>
            </div>
            <div class="text-right">
              <span class="text-5xl text-blue-600">Estimating</span> Trajectory
            </div>
          </h2>
        </div>
      </div>
      <div class="container mx-auto px-8 max-w-6xl">
        <div class="grid grid-cols-3 gap-12 items-center mb-5">
          <div>
            <img src="../assets/images/design_traj.png" 
                alt="RealSense Image" 
                class="rounded-lg max-h-48">
          </div>
          <div class="col-span-2">
            <h2 class="text-2xl text-gray-700 font-bold mb-4">➪ Velocity</h2>
            <p class="text-gray-700 leading-relaxed mb-3">
              To detect a ball throw towards the robot and obtain the initial velocity of the ball, we define two depth planes with one closer and one farther from the sawyer.
              The two points used to compute the initial velocity vector are selected as the first positions that crosses each plane. This setup appears to be more 
              robust towards different ways of throwing the ball and doesn't require computing the velocity constantly which is less susceptible to noise.
            </p>
            <p class="text-gray-500 leading-relaxed">
              <b>Tradeoff: </b>This method is strongly impacted by the FPS of the camera, and requires higher FPS for faster ball velocities. Additionally, 
              the ball must remain in view of the camera until after the second plane which limits the type of trajectories.
            </p>
          </div>
        </div>
        <div class="border-t border-gray-200 mb-5"></div>
        <div class="grid grid-cols-3 gap-12 items-center">
          <div>
            <img src="../assets/images/traj_full.png" 
                alt="Locate Cam Image" 
                class="rounded-lg max-h-48">
          </div>
          <div class="col-span-2">
            <h2 class="text-2xl text-gray-700 font-bold mb-4">➪ Trajectory Prediction</h2>
            <p class="text-gray-700 leading-relaxed mb-3">
              Using the initial velocity, we predict the future positions of the ball by computing projectile motion with basic kinematic equations. We define a strike zone around
              the Sawyer and select the first point in the predicted trajectory that enters the zone as the strike point, which is the target point that the end-effector of 
              the Sawyer needs to reach.
            </p>
            <p class="text-gray-500 leading-relaxed">
              <b>Tradeoff: </b>Forces other than gravity like air drag are ignored, which limits the conditions of operation.
            </p>
          </div>
        </div>
      </div>
    </section>  

    <!-- Intercept Ball -->
    <section id="seeball" class="py-16 bg-white">
      <div class="container mx-auto px-4 mb-12">
        <h2 class="text-4xl font-bold text-gray-800 text-center mb-8">
          <span class="text-5xl text-blue-600">Intercepting</span> the Ball
        </h2>
        <p class="text-gray-600 max-w-3xl mx-auto text-center leading-relaxed">
          Any Summary Sentence (Optional)
        </p>
      </div>
      <div class="container mx-auto px-4 max-w-6xl">
        <div class="grid grid-cols-3 gap-12 items-center mb-5">
          <div>
            <img src="" 
                alt="MPC Image" 
                class="rounded-lg max-h-48">
          </div>
          <div class="col-span-2">
            <h2 class="text-2xl text-gray-700 font-bold mb-4">➪ Model Predictive Control (MPC)</h2>
            <p class="text-gray-700 leading-relaxed">
              (b) Describe the design you chose.
              (c) What design choices did you make when you formulated your design? What trade-offs did you
              have to make?
              (d) How do these design choices impact how well the project meets design criteria that would be
              encountered in a real engineering application, such as robustness, durability, and efficiency?
            </p>
          </div>
        </div>
      </div>
    </section> 

    <!-- Footer -->
    <footer id="resources" class="bg-gray-900 text-white py-8">
      <div class="container mx-auto px-4 text-center">
        <p class="text-gray-400">&copy; EECS/ME C206A Team 8, Fall 2024, UC Berkeley</p>
      </div>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/flowbite@2.5.2/dist/flowbite.min.js"></script>
    <script src="../assets/js/animte_trans_nav.js"></script>
    <script src="../assets/js/mobile_menu_toggle.js"></script>
  </body>
</html>